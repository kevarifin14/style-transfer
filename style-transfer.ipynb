{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage as sk\n",
    "import skimage.io as skio\n",
    "import os\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_images(path):\n",
    "    return skio.imread_collection(['{0}/{1}'.format(path, filename) for filename in os.listdir(path)])\n",
    "\n",
    "train_img = load_images('data/trainB')\n",
    "train_art = load_images('data/trainA')\n",
    "test_img = load_images('data/testB')\n",
    "test_art = load_images('data/testA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ImagePool():\n",
    "    def __init__(self, pool_size):\n",
    "        self.pool_size = pool_size\n",
    "        if self.pool_size > 0:\n",
    "            self.num_imgs = 0\n",
    "            self.images = []\n",
    "\n",
    "    def query(self, images):\n",
    "        if self.pool_size == 0:\n",
    "            return Variable(images)\n",
    "        return_images = []\n",
    "        for image in images:\n",
    "            image = torch.unsqueeze(image, 0)\n",
    "            if self.num_imgs < self.pool_size:\n",
    "                self.num_imgs = self.num_imgs + 1\n",
    "                self.images.append(image)\n",
    "                return_images.append(image)\n",
    "            else:\n",
    "                p = random.uniform(0, 1)\n",
    "                if p > 0.5:\n",
    "                    random_id = random.randint(0, self.pool_size-1)\n",
    "                    tmp = self.images[random_id].clone()\n",
    "                    self.images[random_id] = image\n",
    "                    return_images.append(tmp)\n",
    "                else:\n",
    "                    return_images.append(image)\n",
    "        return_images = Variable(torch.cat(return_images, 0))\n",
    "        return return_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GANLoss(nn.Module):\n",
    "    def __init__(self, real_label=1.0, fake_label=0.0):\n",
    "        super(GANLoss, self).__init__()\n",
    "        self.real_label = real_label\n",
    "        self.fake_label = fake_label\n",
    "        self.real_label_var = None\n",
    "        self.fake_label_var = None\n",
    "        self.loss = nn.MSELoss()\n",
    "    \n",
    "    def get_target_tensor(self, input, target_is_real):\n",
    "        target_tensor = None\n",
    "        if target_is_real:\n",
    "            create_label = ((self.real_label_var is None) or \n",
    "                           (self.real_label_var.numel() != input.numel()))\n",
    "            if create_label:\n",
    "                real_tensor = torch.FloatTensor(input.size()).fill_(self.real_label)\n",
    "                self.real_label_var = Variable(real_tensor, requires_grad=False)\n",
    "            target_tensor = self.real_label_var\n",
    "        else:\n",
    "            create_label = ((self.fake_label_var is None) or \n",
    "                           (self.fake_label_var.numel() != input.numel()))\n",
    "            if create_label:\n",
    "                fake_tensor = torch.FloatTensor(input.size()).fill_(self.fake_label)\n",
    "                self.fake_label_var = Variable(fake_tensor, requires_grad=False)\n",
    "            target_tensor = self.real_label_var \n",
    "        return target_tensor\n",
    "        \n",
    "    def __call__(self, input, target_is_real):\n",
    "        target_tensor = self.get_target_tensor(input, target_is_real)\n",
    "        return self.loss(input, target_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NLayerDiscriminator(nn.Module):\n",
    "    def __init__(self, n_input_channels, n_filters=64, n_layers=3, norm_layer=nn.BatchNorm2d, use_sigmoid=False, gpu_ids=[]):\n",
    "        super(NLayerDiscriminator, self).__init__()\n",
    "        use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        kernel_size = 4\n",
    "        padding_size = 1\n",
    "        sequence = [nn.Conv2d(n_input_channels, n_filters, kernel_size=kernel_size, stride=2, padding=padding_size),\n",
    "                    nn.LeakyReLU(0.2, True)]\n",
    "\n",
    "        n_filters_mult = 1\n",
    "        n_filters_mult_prev = 1\n",
    "        for n in range(1, n_layers):\n",
    "            n_filters_mult_prev = n_filters_mult\n",
    "            nf_mult = min(2**n, 8)\n",
    "            sequence += [nn.Conv2d(n_filters * n_filters_mult_prev, n_filters * n_filters_mult,\n",
    "                                  kernel_size=kernel_size, stride=2, padding=padding_size, bias=use_bias), \n",
    "                        norm_layer(n_filters * n_filters_mult), \n",
    "                        nn.LeakyReLU(0.2, True)]\n",
    "            \n",
    "        n_filters_mult_prev = n_filters_mult\n",
    "        n_filters_mult = min(2**n_layers, 8)\n",
    "        sequence += [nn.Conv2d(n_filters * n_filters_mult_prev, n_filters * n_filters_mult,\n",
    "                              kernel_size=kernel_size, stride=1, padding=padding_size, bias=use_bias), \n",
    "                    norm_layer(n_filters * n_filters_mult),\n",
    "                    nn.LeakyReLU(0.2, True)]\n",
    "        sequence += [nn.Conv2d(n_filters * n_filters_mult, 1, kernel_size=kernel_size, stride=1, padding=padding_size)]\n",
    "        \n",
    "        if use_sigmoid: sequence += [nn.Sigmoid()]\n",
    "        self.model = nn.Sequential(*sequence)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return self.model(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ResNetGenerator(nn.Module):\n",
    "    def __init__(self, n_input_channels, n_output_channels, n_filters=64, norm_layer=nn.BatchNorm2d, use_dropout=False, n_blocks=9, gpu_ids=[], padding_type='reflect'):\n",
    "        super(ResNetGenerator, self).__init__()\n",
    "        self.n_input_channels = n_input_channels\n",
    "        self.n_output_channels = n_output_channels\n",
    "        self.n_filters = n_filters\n",
    "        self.gpu_ids = gpu_ids\n",
    "        use_bias = norm_layer == nn.InstanceNorm2d\n",
    "        \n",
    "        model = [nn.ReflectionPad2d(3),\n",
    "                nn.Conv2d(n_input_channels, n_filters, kernel_size=7, padding=0, bias=use_bias),\n",
    "                norm_layer(n_filters),\n",
    "                nn.ReLU(True)]\n",
    "        \n",
    "        # Downsampling\n",
    "        n_downsampling = 2\n",
    "        for i in range(n_downsampling):\n",
    "            mult = 2**i\n",
    "            model += [nn.Conv2d(n_filters * mult, n_filters * mult * 2, kernel_size=3,\n",
    "                               stride=2, padding=1, bias=use_bias),\n",
    "                     norm_layer(n_filters * mult * 2),\n",
    "                     nn.ReLU(True)]\n",
    "            \n",
    "        # ResNet Blocks\n",
    "        mult = 2**n_downsampling\n",
    "        for i in range(n_blocks):\n",
    "            model += [ResNetBlock(n_filters * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout, use_bias=use_bias)]\n",
    "        \n",
    "        # Upsampling\n",
    "        for i in range(n_downsampling):\n",
    "            mult = 2**(n_downsampling - i)\n",
    "            model += [nn.ConvTranspose2d(n_filters * mult, int(n_filters * mult/2),\n",
    "                                        kernel_size=3, stride=2,\n",
    "                                        padding=1, output_padding=1,\n",
    "                                        bias=use_bias),\n",
    "                     norm_layer(int(n_filters * mult / 2)),\n",
    "                     nn.ReLU(True)]\n",
    "        model += [nn.ReflectionPad2d(3)]\n",
    "        model += [nn.Conv2d(n_filters, n_output_channels, kernel_size=7, padding=0)]\n",
    "        model += [nn.Tanh()]\n",
    "        \n",
    "        self.model = nn.Sequential(*model) \n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet Block "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, use_dropout, use_bias)\n",
    "        \n",
    "    def build_conv_block(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
    "        block = []\n",
    "        p = 0\n",
    "        \n",
    "#         if padding_type == 'reflect': block += [nn.ReflectionPad2d(1)]\n",
    "#         elif padding_type == 'replicate': block += [nn.ReplicationPad2d(1)]\n",
    "#         elif padding_type == 'zero': p = 1\n",
    "            \n",
    "        block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias),\n",
    "                       norm_layer(dim),\n",
    "                       nn.ReLU(True)]\n",
    "        \n",
    "        if use_dropout: \n",
    "            block += [nn.Dropout(0.5)]\n",
    "        \n",
    "        p = 0\n",
    "        if padding_type == 'reflect': block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate': block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero': p = 1\n",
    "            \n",
    "        return nn.Sequential(*block)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = x + self.conv_block(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cycle GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CycleGan():\n",
    "    def __init__(self, train_img, train_art):\n",
    "        size = train_img[0].shape[0]\n",
    "        n_input_channels, n_output_channels = train_img[0].shape[-1], train_img[0].shape[-1]\n",
    "        n_filters = 64\n",
    "        batch_size = 1\n",
    "        lr = 0.0002\n",
    "        beta1 = 0.5\n",
    "        pool_size = 50\n",
    "        \n",
    "        self.input_img = torch.Tensor(batch_size, n_input_channels, size, size)\n",
    "        self.input_art = torch.Tensor(batch_size, n_input_channels, size, size)\n",
    "\n",
    "        self.fake_img_pool = ImagePool(pool_size)\n",
    "        self.fake_art_pool = ImagePool(pool_size)\n",
    "        \n",
    "        # Define G's and D's\n",
    "        self.G_img = ResNetGenerator(n_input_channels, n_input_channels, n_filters)\n",
    "        self.G_art = ResNetGenerator(n_input_channels, n_output_channels, n_filters)\n",
    "        self.D_img = NLayerDiscriminator(3)\n",
    "        self.D_art = NLayerDiscriminator(3)\n",
    "        \n",
    "        # Define loss functions\n",
    "        self.criterion_GAN = GANLoss()\n",
    "        self.criterion_cycle = torch.nn.L1Loss()\n",
    "        self.criterion_identity = torch.nn.L1Loss()\n",
    "        \n",
    "        # Optimizers\n",
    "        self.optimizer_G = torch.optim.Adam(itertools.chain(self.G_img.parameters(), self.G_art.parameters()), \n",
    "                                            lr=lr, betas=(beta1, 0.999))\n",
    "        self.optimizer_D_img = torch.optim.Adam(self.D_img.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "        self.optimizer_D_art = torch.optim.Adam(self.D_art.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "        self.optimizers = [self.optimizer_G, self.optimizer_D_img, self.optimizer_D_art]\n",
    "        self.schedulers = []\n",
    "        for optimizer in self.optimizers:\n",
    "            def lambda_rule(epoch):\n",
    "                epoch_count = 1\n",
    "                niter = 100\n",
    "                niter_decay = 100\n",
    "                lr_l = 1.0 - max(0, epoch + 1 + epoch_count - niter) / float(niter_decay + 1)\n",
    "                return lr_l\n",
    "            scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)\n",
    "            self.schedulers.append(scheduler)\n",
    "    \n",
    "    def set_input(self, input):\n",
    "        self.input_A = input['A']\n",
    "        self.input_B = input['B']\n",
    "        \n",
    "    def forward(self):\n",
    "        self.real_img = Variable(self.input_img)\n",
    "        self.real_art = Variable(self.input_art)\n",
    "        \n",
    "    def backward_D_basic(self, D, real, fake):\n",
    "        # Real\n",
    "        pred_real = D(real)\n",
    "        loss_D_real = self.criterion_GAN(pred_real, True)\n",
    "        # Fake\n",
    "        pred_fake = D(fake.detach())\n",
    "        loss_D_fake = self.criterion_GAN(pred_fake, False)\n",
    "        # Combined Loss\n",
    "        loss_D = (loss_D_real + loss_D_fake) * 0.5\n",
    "        # backward\n",
    "        loss_D.backward()\n",
    "        return loss_D\n",
    "        \n",
    "    def backward_D_img(self):\n",
    "        fake_art = self.fake_art_pool(self.fake_art)\n",
    "        loss_D_img = self.backward_D_basic(self.D_img, self.real_art, fake_art)\n",
    "        self.loss_D_img = loss_D_img.data[0]\n",
    "\n",
    "    def backward_D_art(self):\n",
    "        fake_img = self.fake_img_pool(self.fake_img)\n",
    "        loss_D_art = self.backward_D_basic(self.D_art, self.real_img, fake_img)\n",
    "        self.loss_D_art = loss_D_art.data[0]\n",
    "        \n",
    "    def backward_G(self):\n",
    "        lambda_idt = 0.5\n",
    "        lambda_img = 10.0\n",
    "        lambda_art = 10.0\n",
    "        \n",
    "        # Passing in art to art generator should keep art\n",
    "        idt_img = self.G_img(self.real_art)\n",
    "        loss_idt_img = self.criterion_identity(idt_img, self.real_art) * lambda_art * lambda_idt\n",
    "        \n",
    "        # Passing in images to img generator should keep image\n",
    "        idt_art = self.G_art(self.real_img)\n",
    "        loss_idt_art = self.criterion_identity(idt_art, self.real_art) * lambda_img * lambda_idt\n",
    "        \n",
    "        self.idt_img = idt_img.data\n",
    "        self.idt_art = idt_art.data\n",
    "        self.loss_idt_img = loss_idt_img.data[0]\n",
    "        self.loss_idt_art = loss_idt_art.data[0]\n",
    "        \n",
    "        # GAN loss for generating fake art\n",
    "        fake_art = self.G_img(self.real_img)\n",
    "        pred_fake = self.D_img(fake_art)\n",
    "        loss_G_img = self.criterionGAN(pred_fake, True)\n",
    "        \n",
    "        # GAN loss for generating fake images\n",
    "        fake_img = self.G_art(self.real_art)\n",
    "        pred_fake = self.D_art(fake_img)\n",
    "        loss_G_art = self.criterionGAN(pred_fake, True)\n",
    "        \n",
    "        # Forward cycle loss\n",
    "        rec_img = self.G_art(fake_art)\n",
    "        loss_cycle_img = self.criterion_cycle(rec_img, self.real_img) * lambda_img\n",
    "        \n",
    "        # Backward cycle loss \n",
    "        rec_art = self.G_img(fake_img)\n",
    "        loss_cycle_art = self.criterion_cycle(rec_art, self.real_art) * lambda_art\n",
    "        \n",
    "        loss_G = loss_G_img + loss_G_art + loss_cycle_img + loss_cycle_art + loss_idt_img + loss_idt_art\n",
    "        loss_G.backward()\n",
    "        \n",
    "        self.fake_art = fake_art.data\n",
    "        self.fake_img = fake_img.data\n",
    "        self.rec_img = rec_img.data\n",
    "        self.rec_art = rec_art.data\n",
    "        \n",
    "        self.loss_G_img = loss_G_img.data[0]\n",
    "        self.loss_G_art = loss_G_art.data[0]\n",
    "        self.loss_cycle_img = loss_cycle_img.data[0]\n",
    "        self.loss_cycle_art = loss_cycle_art.data[0]\n",
    "        \n",
    "    def optimize_parameters(self):\n",
    "        self.forward()\n",
    "        self.optimizer_G.zero_grad()\n",
    "        self.backward_G()\n",
    "        self.opimtizer_G.step()\n",
    "        \n",
    "        self.optimizer_D_img.zero_grad()\n",
    "        self.backward_D_img()\n",
    "        self.optimizer_D_img.step()\n",
    "        \n",
    "        self.optimizer_D_art.zero_grad()\n",
    "        self.backward_D_art()\n",
    "        self.optimizer_D_art.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Options():\n",
    "    def __init__(self):\n",
    "        self.niter = 100\n",
    "        self.niter_decay = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CycleGan' object has no attribute 'criterionGAN'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-c187aea1cd18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'A'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'B'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_art\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'works'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-116-692782752676>\u001b[0m in \u001b[0;36moptimize_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_G\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopimtizer_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-116-692782752676>\u001b[0m in \u001b[0;36mbackward_G\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mfake_art\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mpred_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_art\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mloss_G_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterionGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# GAN loss for generating fake images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CycleGan' object has no attribute 'criterionGAN'"
     ]
    }
   ],
   "source": [
    "model = CycleGan(train_img, train_art)\n",
    "options = Options()\n",
    "\n",
    "for epoch in range(options.niter + options.niter_decay):\n",
    "    for i, _ in enumerate(train_img):\n",
    "        data = {'A': train_img[i], 'B': train_art[i]}\n",
    "        model.set_input(data)\n",
    "        model.optimize_parameters()\n",
    "        print('works')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
